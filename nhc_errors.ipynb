{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71748d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP TO CHECKPOINT and only run from there (to use the precomputed .parquet file)\n",
    "#   (otherwise it will take several minutes)\n",
    "\n",
    "# The following is based on RI analysis from the following paper\n",
    "# https://journals.ametsoc.org/view/journals/wefo/35/6/WAF-D-19-0253.1.xml#bib15\n",
    "# This notebook has only done Atlantic RI)\n",
    "\n",
    "# Note: as in the paper above, there is some overlap for rapid intensification events and forecasts\n",
    "# an example would be: RI in 24h in one forecast, and then a subsequent forecast 12 hours later has the 12h with RI\n",
    "# this results in some overlap (double counting)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "filepath_ti_errs_atl = '1989-present_OFCL_v_BCD5_ind_ATL_TI_errors.txt'\n",
    "filepath_ti_errs_pac = '1989-present_OFCL_v_BCD5_ind_EPAC_TI_errors.txt'\n",
    "filepath_ac_errs_atl = '1989-present_OFCL_v_BCD5_ind_ATL_AC_errors.txt'\n",
    "filepath_ac_errs_pac = '1989-present_OFCL_v_BCD5_ind_EPAC_AC_errors.txt'\n",
    "\n",
    "# only considering track intensity errors for the atlantic (filepath_ti_errs_atl) in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568d28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_intensity_err(filepath):\n",
    "    header = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        # header lines\n",
    "        ln = f.readline().strip()\n",
    "        header['basin'] = ln.split(':')[1].strip()\n",
    "        ln = f.readline().strip()\n",
    "        header['models'] = ln.split(':')[1].strip().split(' ')\n",
    "        ln = f.readline().strip()\n",
    "        header['kt_range'] = ln.split(':')[1].strip()\n",
    "        ln = f.readline().strip()\n",
    "        header['subtropical'] = ln\n",
    "        ln = f.readline().strip()\n",
    "        header['extratropical'] = ln\n",
    "        ln = f.readline().strip()\n",
    "        header['dissipation'] = ln\n",
    "        \n",
    "        # only keep columns for official forecasts (drop baseline forecasts)\n",
    "        if header['models'][0] == 'OFCL':\n",
    "            drop_match_str1 = 'hI02'\n",
    "            drop_match_str2 = 'hT02'\n",
    "        else:\n",
    "            drop_match_str1 = 'hI01'\n",
    "            drop_match_str2 = 'hT01'\n",
    "\n",
    "        # line space between header and data\n",
    "        ln = f.readline().strip()\n",
    "        \n",
    "        # line with column names\n",
    "        ln = f.readline().strip()\n",
    "        column_names = list(filter(None,ln.split(' ')))\n",
    "        \n",
    "        drop_columns = []\n",
    "        for column_name in column_names:\n",
    "            if drop_match_str1 in column_name or drop_match_str2 in column_name:\n",
    "                drop_columns.append(column_name)\n",
    "        \n",
    "        # loop over the data\n",
    "        data = []\n",
    "        while True:\n",
    "            ln = f.readline()\n",
    "            if not ln:\n",
    "                break\n",
    "            ln = ln.strip()\n",
    "            row = list(filter(None,ln.split(' ')))\n",
    "            data.append(row)\n",
    "\n",
    "        # Create the pandas DataFrame\n",
    "        df = pd.DataFrame(data, columns = column_names)\n",
    "        # convert the time column to panda timestamp\n",
    "        df['Date/Time'] = pd.to_datetime(df['Date/Time'], dayfirst=True)\n",
    "        # rename it to 'ds' to be shorter\n",
    "        df.rename(columns={'Date/Time': 'ds'}, inplace=True)\n",
    "        # drop columns from base line forecast (CLIPER5 or SHIFOR5) and keep OFCL\n",
    "        df.drop(columns=drop_columns, inplace=True)\n",
    "        for column_name in list(df.keys()):\n",
    "            if column_name != 'ds' and column_name != 'STMID': \n",
    "                df[column_name] = df[column_name].astype(float)\n",
    "        # replace missing values (-9999) with NaN\n",
    "        df.replace(-9999.0, np.NaN, inplace=True)\n",
    "        # convert all but 'ds' and 'STMID' from string to float now\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return [header, df]\n",
    "\n",
    "def is_rapid_intensification(valid_h, base_intensity, valid_intensity):\n",
    "    ri = False\n",
    "    if np.isnan(base_intensity) or np.isnan(valid_intensity):\n",
    "        return ri\n",
    "    if valid_h == 0:\n",
    "        # don't do RI for base time (000h)\n",
    "        return ri\n",
    "    # https://journals.ametsoc.org/view/journals/wefo/35/6/WAF-D-19-0253.1.xml#bib15\n",
    "    # 'RI is therefore defined as an increase of at least 20 kt in 12 h, 30 kt in 24 h, 45 kt in 36 h, and 55 kt in 48 h'\n",
    "    intensity_change = valid_intensity - base_intensity\n",
    "    rapid_intensification_threshold = np.NaN\n",
    "    if valid_h <= 12:\n",
    "        rapid_intensification_threshold = 20\n",
    "    elif valid_h <= 24:\n",
    "        rapid_intensification_threshold = 30\n",
    "    elif valid_h <= 36:\n",
    "        rapid_intensification_threshold = 45\n",
    "    elif valid_h <= 48:\n",
    "        rapid_intensification_threshold = 55\n",
    "    # only consider rapid intensification for the above periods\n",
    "    if np.isnan(rapid_intensification_threshold):\n",
    "        return ri\n",
    "    if (intensity_change >= rapid_intensification_threshold):\n",
    "        ri = True\n",
    "    return ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e19d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a11025",
   "metadata": {},
   "outputs": [],
   "source": [
    "[header, df] = read_intensity_err(filepath_ti_errs_atl)\n",
    "# track and intensity (used for naming files)\n",
    "error_category = 'TI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033676b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356f1a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_838862/4206277511.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[best_intensity_rapid_intensification_column_name] = False\n",
      "/tmp/ipykernel_838862/4206277511.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[forecast_intensity_change_column_name] = np.NaN\n",
      "/tmp/ipykernel_838862/4206277511.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[best_intensity_change_column_name] = np.NaN\n",
      "/tmp/ipykernel_838862/4206277511.py:74: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['FRI'] = False\n",
      "/tmp/ipykernel_838862/4206277511.py:75: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['FRI_count'] = 0\n",
      "/tmp/ipykernel_838862/4206277511.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['BRI'] = False\n",
      "/tmp/ipykernel_838862/4206277511.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['BRI_count'] = 0\n"
     ]
    }
   ],
   "source": [
    "# create mappings and create new columns for calculations and analysis\n",
    "\n",
    "column_names = list(df.keys())\n",
    "# examples of column names with 48 hours in parenthesis\n",
    "# (48hI01) intensity valid forecast hours\n",
    "intensity_err_column_name_to_hour = {}\n",
    "intensity_err_hour_to_column_name = {}\n",
    "# (48hFI) forecast intensity for valid hours of the forecast (missing so recalculate from data)\n",
    "forecast_intensity_column_name_to_hour = {}\n",
    "forecast_intensity_hour_to_column_name = {}\n",
    "# (48hBI) best intensity for valid hours of the forecast\n",
    "best_intensity_column_name_to_hour = {}\n",
    "best_intensity_hour_to_column_name = {}\n",
    "# (48hFRI) forecast rapid intensification\n",
    "forecast_rapid_intensification_column_name_to_hour = {}\n",
    "forecast_rapid_intensification_hour_to_column_name = {}\n",
    "# (48hBRI) best intensity rapid intensification\n",
    "best_intensity_rapid_intensification_column_name_to_hour = {}\n",
    "best_intensity_rapid_intensification_hour_to_column_name = {}\n",
    "# (48hDFI) changes in forecast intensity from base time to valid hour\n",
    "forecast_intensity_change_column_name_to_hour = {}\n",
    "forecast_intensity_change_hour_to_column_name = {}\n",
    "# (48hDBI) changes in best intensity from base time to valid hour\n",
    "best_intensity_change_column_name_to_hour = {}\n",
    "best_intensity_change_hour_to_column_name = {}\n",
    "\n",
    "for column_name in column_names:\n",
    "    if 'hI' in column_name:\n",
    "        # create mappings from intensity column names to hour\n",
    "        h = int(column_name.split('hI')[0])\n",
    "        intensity_err_column_name_to_hour[column_name] = h\n",
    "        intensity_err_hour_to_column_name[h] = column_name\n",
    "        \n",
    "        # create extra columns for forecast intensity for each forecast hour\n",
    "        forecast_intensity_column_name = f'{h}hFI'\n",
    "        df[forecast_intensity_column_name] = np.NaN\n",
    "        forecast_intensity_column_name_to_hour[forecast_intensity_column_name] = h\n",
    "        forecast_intensity_hour_to_column_name[h] = forecast_intensity_column_name\n",
    "        \n",
    "        # create extra columns for best intensity for each forecast hour\n",
    "        best_intensity_column_name = f'{h}hBI'\n",
    "        df[best_intensity_column_name] = np.NaN\n",
    "        best_intensity_column_name_to_hour[best_intensity_column_name] = h\n",
    "        best_intensity_hour_to_column_name[h] = best_intensity_column_name\n",
    "\n",
    "        # create extra columns for forecast RI categorization for each forecast hour\n",
    "        forecast_rapid_intensification_column_name = f'{h}hFRI'\n",
    "        df[forecast_rapid_intensification_column_name] = False\n",
    "        forecast_rapid_intensification_column_name_to_hour[forecast_rapid_intensification_column_name] = h\n",
    "        forecast_rapid_intensification_hour_to_column_name[h] = forecast_rapid_intensification_column_name\n",
    "        \n",
    "        # create extra columns for best intensity RI categorization for each forecast hour\n",
    "        best_intensity_rapid_intensification_column_name = f'{h}hBRI'\n",
    "        df[best_intensity_rapid_intensification_column_name] = False\n",
    "        best_intensity_rapid_intensification_column_name_to_hour[best_intensity_rapid_intensification_column_name] = h\n",
    "        best_intensity_rapid_intensification_hour_to_column_name[h] = best_intensity_rapid_intensification_column_name\n",
    "        \n",
    "        # create extra columns for changes in forecast intensity for each forecast hour\n",
    "        # (forecast intensity at valid hour - forecast intensity at base hour)\n",
    "        forecast_intensity_change_column_name = f'{h}hDFI'\n",
    "        df[forecast_intensity_change_column_name] = np.NaN\n",
    "        forecast_intensity_change_column_name_to_hour[forecast_intensity_change_column_name] = h\n",
    "        forecast_intensity_change_hour_to_column_name[h] = forecast_intensity_change_column_name\n",
    "        \n",
    "        # create extra columns for changes in (best) intensity for each forecast hour\n",
    "        # (best intensity at valid hour (from other row) - best intensity at base hour)\n",
    "        best_intensity_change_column_name = f'{h}hDBI'\n",
    "        df[best_intensity_change_column_name] = np.NaN\n",
    "        best_intensity_change_column_name_to_hour[best_intensity_change_column_name] = h\n",
    "        best_intensity_change_hour_to_column_name[h] = best_intensity_change_column_name\n",
    "\n",
    "# column for if any of the forecast hours show rapid intensification\n",
    "# (forecast) rapid intensification\n",
    "df['FRI'] = False\n",
    "df['FRI_count'] = 0\n",
    "\n",
    "# column for if any of the (best intensity) valid hours of a forecast show rapid intensification\n",
    "# (best intensity) rapid intensification\n",
    "df['BRI'] = False\n",
    "df['BRI_count'] = 0\n",
    "\n",
    "# defragment frame (for performance)\n",
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5318540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate forecast intensities and rapid intensification\n",
    "\n",
    "# make sure to sort so that we always calculate the forecast_base_intensity first in the inner loop below\n",
    "sorted_intensity_err_hour_to_column_name_items = sorted(intensity_err_hour_to_column_name.items(), key=lambda x:x[0])\n",
    "\n",
    "for idx in range(0, len(df)):\n",
    "    base_time = df.iloc[idx]['ds']\n",
    "    stmid = df.iloc[idx]['STMID']\n",
    "    forecast_base_intensity = np.NaN\n",
    "    forecast_rapid_intensification_any = False\n",
    "    best_intensity_rapid_intensification_any = False\n",
    "    for [valid_h, valid_column_name] in sorted_intensity_err_hour_to_column_name_items:\n",
    "        intensity_err = df.loc[idx][valid_column_name]\n",
    "        best_intensity = df.loc[idx]['WS']\n",
    "        if not np.isnan(intensity_err):\n",
    "            valid_time = base_time + timedelta(hours=valid_h)\n",
    "            valid_best_intensity_row = df.loc[(df['ds'] == valid_time) & (df['STMID'] == stmid)]\n",
    "            if not valid_best_intensity_row.empty:\n",
    "                valid_best_intensity = valid_best_intensity_row['WS'].iloc[0]\n",
    "                if not np.isnan(valid_best_intensity):\n",
    "                    # calculate forecast intensity from error and best_intensity\n",
    "                    forecast_intensity = valid_best_intensity + intensity_err\n",
    "\n",
    "                    # set the base intensity for this forecast\n",
    "                    if valid_h == 0:\n",
    "                        forecast_base_intensity = forecast_intensity\n",
    "                    \n",
    "                    # set forecast intensity for valid hour\n",
    "                    forecast_intensity_column_name = forecast_intensity_hour_to_column_name[valid_h]\n",
    "                    df.at[idx, forecast_intensity_column_name] = forecast_intensity\n",
    "                    \n",
    "                    # set best intensity for valid hour\n",
    "                    best_intensity_column_name = best_intensity_hour_to_column_name[valid_h]\n",
    "                    df.at[idx, best_intensity_column_name] = valid_best_intensity\n",
    "\n",
    "                    # calculate forecast rapid intensification for (selected) forecast hours\n",
    "                    forecast_rapid_intensification_column_name = forecast_rapid_intensification_hour_to_column_name[valid_h]\n",
    "                    forecast_rapid_intensification = is_rapid_intensification(valid_h, forecast_base_intensity, forecast_intensity)\n",
    "                    df.at[idx, forecast_rapid_intensification_column_name] = forecast_rapid_intensification\n",
    "                    if forecast_rapid_intensification:\n",
    "                        df.at[idx, 'FRI_count'] = df.at[idx, 'FRI_count'] + 1\n",
    "                        forecast_rapid_intensification_any = True\n",
    "                    \n",
    "                    # calculate best intensity rapid intensification for (selected) forecast hours\n",
    "                    best_intensity_rapid_intensification_column_name = best_intensity_rapid_intensification_hour_to_column_name[valid_h]\n",
    "                    best_intensity_rapid_intensification = is_rapid_intensification(valid_h, best_intensity, valid_best_intensity)\n",
    "                    df.at[idx, best_intensity_rapid_intensification_column_name] = best_intensity_rapid_intensification\n",
    "                    if best_intensity_rapid_intensification:\n",
    "                        df.at[idx, 'BRI_count'] = df.at[idx, 'BRI_count'] + 1\n",
    "                        best_intensity_rapid_intensification_any = True\n",
    "                    \n",
    "                    # calculate the change in forecast intensity at valid hour\n",
    "                    forecast_intensity_change = forecast_intensity - forecast_base_intensity\n",
    "                    forecast_intensity_change_column_name = forecast_intensity_change_hour_to_column_name[valid_h]\n",
    "                    df.at[idx, forecast_intensity_change_column_name] = forecast_intensity_change\n",
    "                    \n",
    "                    # calculate the change in best intensity at valid hour\n",
    "                    best_intensity_change = valid_best_intensity - best_intensity\n",
    "                    best_intensity_change_column_name = best_intensity_change_hour_to_column_name[valid_h]\n",
    "                    df.at[idx, best_intensity_change_column_name] = best_intensity_change\n",
    "                else:\n",
    "                    print(f\"Warning: best_intensity data not available for {valid_h} from forecast index {idx}...\")\n",
    "            else:\n",
    "                # raise warning\n",
    "                # miss best_intensity calculations if there is no best track 'ws' data here?\n",
    "                print(f\"Warning: no forecast row for {valid_h} starting from forecast index {idx}...\")\n",
    "    df.at[idx, 'FRI'] = forecast_rapid_intensification_any\n",
    "    df.at[idx, 'BRI'] = best_intensity_rapid_intensification_any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1445f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ds',\n",
       " 'STMID',\n",
       " 'F012',\n",
       " 'F024',\n",
       " 'F036',\n",
       " 'F048',\n",
       " 'F060',\n",
       " 'F072',\n",
       " 'F096',\n",
       " 'F120',\n",
       " 'F144',\n",
       " 'F168',\n",
       " 'Lat',\n",
       " 'Lon',\n",
       " 'WS',\n",
       " '000hT01',\n",
       " '012hT01',\n",
       " '024hT01',\n",
       " '036hT01',\n",
       " '048hT01',\n",
       " '060hT01',\n",
       " '072hT01',\n",
       " '096hT01',\n",
       " '120hT01',\n",
       " '144hT01',\n",
       " '168hT01',\n",
       " '000hI01',\n",
       " '012hI01',\n",
       " '024hI01',\n",
       " '036hI01',\n",
       " '048hI01',\n",
       " '060hI01',\n",
       " '072hI01',\n",
       " '096hI01',\n",
       " '120hI01',\n",
       " '144hI01',\n",
       " '168hI01',\n",
       " '0hFI',\n",
       " '0hBI',\n",
       " '0hFRI',\n",
       " '0hBRI',\n",
       " '0hDFI',\n",
       " '0hDBI',\n",
       " '12hFI',\n",
       " '12hBI',\n",
       " '12hFRI',\n",
       " '12hBRI',\n",
       " '12hDFI',\n",
       " '12hDBI',\n",
       " '24hFI',\n",
       " '24hBI',\n",
       " '24hFRI',\n",
       " '24hBRI',\n",
       " '24hDFI',\n",
       " '24hDBI',\n",
       " '36hFI',\n",
       " '36hBI',\n",
       " '36hFRI',\n",
       " '36hBRI',\n",
       " '36hDFI',\n",
       " '36hDBI',\n",
       " '48hFI',\n",
       " '48hBI',\n",
       " '48hFRI',\n",
       " '48hBRI',\n",
       " '48hDFI',\n",
       " '48hDBI',\n",
       " '60hFI',\n",
       " '60hBI',\n",
       " '60hFRI',\n",
       " '60hBRI',\n",
       " '60hDFI',\n",
       " '60hDBI',\n",
       " '72hFI',\n",
       " '72hBI',\n",
       " '72hFRI',\n",
       " '72hBRI',\n",
       " '72hDFI',\n",
       " '72hDBI',\n",
       " '96hFI',\n",
       " '96hBI',\n",
       " '96hFRI',\n",
       " '96hBRI',\n",
       " '96hDFI',\n",
       " '96hDBI',\n",
       " '120hFI',\n",
       " '120hBI',\n",
       " '120hFRI',\n",
       " '120hBRI',\n",
       " '120hDFI',\n",
       " '120hDBI',\n",
       " '144hFI',\n",
       " '144hBI',\n",
       " '144hFRI',\n",
       " '144hBRI',\n",
       " '144hDFI',\n",
       " '144hDBI',\n",
       " '168hFI',\n",
       " '168hBI',\n",
       " '168hFRI',\n",
       " '168hBRI',\n",
       " '168hDFI',\n",
       " '168hDBI',\n",
       " 'FRI',\n",
       " 'FRI_count',\n",
       " 'BRI',\n",
       " 'BRI_count']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f346db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NHC_OFCL_ATLANTIC_1989-2022_TI.parquet\n"
     ]
    }
   ],
   "source": [
    "# save computation\n",
    "#df.to_parquet()\n",
    "file_name_parquet = 'NHC_OFCL_' + header['basin'].replace(' ', '_') + '_' + error_category + '.parquet'\n",
    "df.to_parquet(file_name_parquet)\n",
    "print(file_name_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b56ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307bb00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd8bc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929a42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "file_name_parquet = 'NHC_OFCL_ATLANTIC_1989-2022_TI.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26ff868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ri = pd.read_parquet(file_name_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eedafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated as above (without df modifications) so it works with checkpointing\n",
    "# create mappings and create new columns for calculations and analysis\n",
    "\n",
    "column_names = list(df.keys())\n",
    "# examples of column names with 48 hours in parenthesis\n",
    "# (48hI01) intensity valid forecast hours\n",
    "intensity_err_column_name_to_hour = {}\n",
    "intensity_err_hour_to_column_name = {}\n",
    "# (48hFI) forecast intensity for valid hours of the forecast (missing so recalculate from data)\n",
    "forecast_intensity_column_name_to_hour = {}\n",
    "forecast_intensity_hour_to_column_name = {}\n",
    "# (48hBI) best intensity for valid hours of the forecast\n",
    "best_intensity_column_name_to_hour = {}\n",
    "best_intensity_hour_to_column_name = {}\n",
    "# (48hFRI) forecast rapid intensification\n",
    "forecast_rapid_intensification_column_name_to_hour = {}\n",
    "forecast_rapid_intensification_hour_to_column_name = {}\n",
    "# (48hBRI) best intensity rapid intensification\n",
    "best_intensity_rapid_intensification_column_name_to_hour = {}\n",
    "best_intensity_rapid_intensification_hour_to_column_name = {}\n",
    "# (48hDFI) changes in forecast intensity from base time to valid hour\n",
    "forecast_intensity_change_column_name_to_hour = {}\n",
    "forecast_intensity_change_hour_to_column_name = {}\n",
    "# (48hDBI) changes in best intensity from base time to valid hour\n",
    "best_intensity_change_column_name_to_hour = {}\n",
    "best_intensity_change_hour_to_column_name = {}\n",
    "\n",
    "for column_name in column_names:\n",
    "    if 'hI' in column_name:\n",
    "        # create mappings from intensity column names to hour\n",
    "        h = int(column_name.split('hI')[0])\n",
    "        intensity_err_column_name_to_hour[column_name] = h\n",
    "        intensity_err_hour_to_column_name[h] = column_name\n",
    "        \n",
    "        # create extra columns for forecast intensity for each forecast hour\n",
    "        forecast_intensity_column_name = f'{h}hFI'\n",
    "        forecast_intensity_column_name_to_hour[forecast_intensity_column_name] = h\n",
    "        forecast_intensity_hour_to_column_name[h] = forecast_intensity_column_name\n",
    "        \n",
    "        # create extra columns for best intensity for each forecast hour\n",
    "        best_intensity_column_name = f'{h}hBI'\n",
    "        best_intensity_column_name_to_hour[best_intensity_column_name] = h\n",
    "        best_intensity_hour_to_column_name[h] = best_intensity_column_name\n",
    "\n",
    "        # create extra columns for forecast RI categorization for each forecast hour\n",
    "        forecast_rapid_intensification_column_name = f'{h}hFRI'\n",
    "        forecast_rapid_intensification_column_name_to_hour[forecast_rapid_intensification_column_name] = h\n",
    "        forecast_rapid_intensification_hour_to_column_name[h] = forecast_rapid_intensification_column_name\n",
    "        \n",
    "        # create extra columns for best intensity RI categorization for each forecast hour\n",
    "        best_intensity_rapid_intensification_column_name = f'{h}hBRI'\n",
    "        best_intensity_rapid_intensification_column_name_to_hour[best_intensity_rapid_intensification_column_name] = h\n",
    "        best_intensity_rapid_intensification_hour_to_column_name[h] = best_intensity_rapid_intensification_column_name\n",
    "        \n",
    "        # create extra columns for changes in forecast intensity for each forecast hour\n",
    "        # (forecast intensity at valid hour - forecast intensity at base hour)\n",
    "        forecast_intensity_change_column_name = f'{h}hDFI'\n",
    "        forecast_intensity_change_column_name_to_hour[forecast_intensity_change_column_name] = h\n",
    "        forecast_intensity_change_hour_to_column_name[h] = forecast_intensity_change_column_name\n",
    "        \n",
    "        # create extra columns for changes in (best) intensity for each forecast hour\n",
    "        # (best intensity at valid hour (from other row) - best intensity at base hour)\n",
    "        best_intensity_change_column_name = f'{h}hDBI'\n",
    "        best_intensity_change_column_name_to_hour[best_intensity_change_column_name] = h\n",
    "        best_intensity_change_hour_to_column_name[h] = best_intensity_change_column_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0311d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "######## STATS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05573743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for storms with forecast intensity rapid intensification\n",
      "===================================================================\n",
      "Number of forecast rapid intensification events on a valid hour: 186\n",
      "Number of forecasts with a forecast rapid intensification event on a valid hour: 118\n",
      "65 Storms with rapid intensification in forecast:\n",
      "{'AL091996', 'AL192020', 'AL152022', 'AL072010', 'AL262020', 'AL051996', 'AL052000', 'AL091993', 'AL142018', 'AL132022', 'AL092017', 'AL062002', 'AL282020', 'AL131998', 'AL112001', 'AL072000', 'AL122021', 'AL131996', 'AL052019', 'AL101996', 'AL132020', 'AL092022', 'AL042005', 'AL061996', 'AL071993', 'AL042009', 'AL031998', 'AL182005', 'AL252005', 'AL062006', 'AL112017', 'AL051993', 'AL041999', 'AL131999', 'AL312020', 'AL081996', 'AL172008', 'AL292020', 'AL112000', 'AL061991', 'AL092021', 'AL182021', 'AL041996', 'AL102000', 'AL191995', 'AL031996', 'AL051997', 'AL132002', 'AL152001', 'AL041992', 'AL101995', 'AL021998', 'AL071992', 'AL052001', 'AL142017', 'AL132010', 'AL112010', 'AL132000', 'AL202020', 'AL072008', 'AL011994', 'AL032001', 'AL062018', 'AL111996', 'AL051998'}\n",
      "\n",
      "Number of forecast rapid intensification events for each forecast valid hour:\n",
      "12hFRI : 86\n",
      "24hFRI : 67\n",
      "36hFRI : 21\n",
      "48hFRI : 12\n",
      "\n",
      "Table 1.\n",
      "Forecast intensity error for forecast rapid intensification (columns are forecast valid hours):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.883721</td>\n",
       "      <td>-1.641791</td>\n",
       "      <td>-6.904762</td>\n",
       "      <td>-1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.503570</td>\n",
       "      <td>18.553527</td>\n",
       "      <td>14.359334</td>\n",
       "      <td>14.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-12.500000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>12.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              12         24         36         48\n",
       "count  86.000000  67.000000  21.000000  12.000000\n",
       "mean   -0.883721  -1.641791  -6.904762  -1.250000\n",
       "std    12.503570  18.553527  14.359334  14.000812\n",
       "min   -60.000000 -40.000000 -35.000000 -30.000000\n",
       "10%   -15.000000 -25.000000 -30.000000 -23.000000\n",
       "25%    -5.000000 -12.500000 -15.000000  -5.000000\n",
       "50%     0.000000   0.000000  -5.000000   0.000000\n",
       "75%     5.000000   7.500000   0.000000   6.250000\n",
       "90%    12.500000  20.000000  10.000000  14.500000\n",
       "max    30.000000  45.000000  15.000000  15.000000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### statistics for forecasted rapid intensification (FRI)\n",
    "### (forecast RI)\n",
    "\n",
    "print(\"Statistics for storms with forecast intensity rapid intensification\")\n",
    "print(\"===================================================================\")\n",
    "\n",
    "fri_num_events = df_ri.loc[df_ri['FRI'] == True]['FRI_count'].sum()\n",
    "fri_forecast_count = len(df_ri.loc[df_ri['FRI'] == True])\n",
    "print(f\"Number of forecast rapid intensification events on a valid hour: {fri_num_events}\")\n",
    "print(f\"Number of forecasts with a forecast rapid intensification event on a valid hour: {fri_forecast_count}\")\n",
    "fri_storm_ids = set()\n",
    "for idx in df_ri.loc[df_ri['FRI'] == True].index:\n",
    "    fri_storm_ids.add(df_ri.at[idx,'STMID'])\n",
    "print(f\"{len(fri_storm_ids)} Storms with rapid intensification in forecast:\")\n",
    "print(fri_storm_ids)\n",
    "print(\"\")\n",
    "\n",
    "fri_errors = {}\n",
    "print(\"Number of forecast rapid intensification events for each forecast valid hour:\")\n",
    "for column_name in forecast_rapid_intensification_column_name_to_hour.keys():\n",
    "    fri_rows = df_ri.loc[df_ri[column_name] == True]\n",
    "    count = len(fri_rows)\n",
    "    if count > 0:\n",
    "        print(f\"{column_name} : {count}\")\n",
    "    \n",
    "    valid_h = forecast_rapid_intensification_column_name_to_hour[column_name]\n",
    "    intensity_err_column_name = intensity_err_hour_to_column_name[valid_h]\n",
    "    fri_errors[valid_h] = []\n",
    "    for idx in fri_rows.index:\n",
    "        prev_fri = fri_errors[valid_h]\n",
    "        intensity_err = fri_rows.at[idx,intensity_err_column_name]\n",
    "        prev_fri.append(intensity_err)\n",
    "        fri_errors[valid_h] = prev_fri\n",
    "\n",
    "# remove empty keys\n",
    "fri_errors = dict((k, v) for k, v in fri_errors.items() if v)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Table 1.\")\n",
    "# convert to dataframe and compute some stats\n",
    "print(\"Forecast intensity error for forecast rapid intensification (columns are forecast valid hours):\")\n",
    "df_fri_errors = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in fri_errors.items() ]))\n",
    "df_fri_errors.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fee429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af9bb2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for storms with best intensity rapid intensification:\n",
      "================================================================\n",
      "Number of best intensity rapid intensification events on valid hours: 1679\n",
      "Number of forecasts with a best intensity rapid intensification event on a valid hour: 945\n",
      "181 Storms with best intensity rapid intensification:\n",
      "\n",
      "{'AL091996', 'AL052005', 'AL042008', 'AL161990', 'AL072010', 'AL262020', 'AL051996', 'AL021996', 'AL052022', 'AL182010', 'AL082002', 'AL142016', 'AL142018', 'AL092013', 'AL091998', 'AL282020', 'AL142010', 'AL172010', 'AL122021', 'AL032008', 'AL092006', 'AL101996', 'AL102019', 'AL092004', 'AL082006', 'AL042009', 'AL182005', 'AL092007', 'AL041999', 'AL062007', 'AL172008', 'AL102001', 'AL122005', 'AL072009', 'AL162016', 'AL041996', 'AL132019', 'AL182021', 'AL112004', 'AL072021', 'AL082022', 'AL021995', 'AL132010', 'AL132000', 'AL011995', 'AL051992', 'AL082014', 'AL062015', 'AL032001', 'AL122004', 'AL071997', 'AL062018', 'AL032005', 'AL032000', 'AL082020', 'AL032018', 'AL122010', 'AL091995', 'AL151995', 'AL111994', 'AL042001', 'AL132003', 'AL122011', 'AL112009', 'AL182012', 'AL072000', 'AL112015', 'AL041998', 'AL071998', 'AL042005', 'AL071993', 'AL141998', 'AL112017', 'AL031998', 'AL252005', 'AL042015', 'AL312020', 'AL102003', 'AL081996', 'AL222020', 'AL112000', 'AL052002', 'AL052012', 'AL182011', 'AL162018', 'AL051997', 'AL202010', 'AL122007', 'AL132012', 'AL071995', 'AL152017', 'AL072022', 'AL032012', 'AL072008', 'AL202020', 'AL022011', 'AL122000', 'AL122017', 'AL051998', 'AL052021', 'AL101990', 'AL192020', 'AL072018', 'AL152016', 'AL082012', 'AL051995', 'AL091993', 'AL092017', 'AL112001', 'AL102002', 'AL072017', 'AL061992', 'AL171995', 'AL131996', 'AL132017', 'AL052019', 'AL132020', 'AL081999', 'AL022008', 'AL292020', 'AL042004', 'AL142000', 'AL032014', 'AL102000', 'AL191995', 'AL092011', 'AL101995', 'AL112012', 'AL142017', 'AL112010', 'AL292005', 'AL152008', 'AL072001', 'AL272005', 'AL172000', 'AL051990', 'AL072016', 'AL101998', 'AL042007', 'AL162007', 'AL162017', 'AL081993', 'AL031990', 'AL162011', 'AL142020', 'AL131998', 'AL092020', 'AL152000', 'AL092022', 'AL012006', 'AL131995', 'AL032004', 'AL031991', 'AL062006', 'AL212010', 'AL082008', 'AL131999', 'AL012004', 'AL272020', 'AL092021', 'AL061991', 'AL162022', 'AL022018', 'AL202005', 'AL031996', 'AL132002', 'AL152001', 'AL041992', 'AL012016', 'AL021998', 'AL062001', 'AL072006', 'AL132004', 'AL062010', 'AL091999', 'AL031999', 'AL062004', 'AL132007', 'AL041994', 'AL092008', 'AL161999'}\n",
      "\n",
      "Number of best intensity rapid intensification events for each forecast valid hour:\n",
      "12hBRI : 459\n",
      "24hBRI : 565\n",
      "36hBRI : 340\n",
      "48hBRI : 315\n",
      "\n",
      "Table 2.\n",
      "Forecast intensity error for best intensity rapid intensification (columns are forecast valid hours):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>459.000000</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>315.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-17.159041</td>\n",
       "      <td>-23.283186</td>\n",
       "      <td>-32.411765</td>\n",
       "      <td>-36.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.422331</td>\n",
       "      <td>11.262085</td>\n",
       "      <td>14.097464</td>\n",
       "      <td>15.243814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>-95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               12          24          36          48\n",
       "count  459.000000  565.000000  340.000000  315.000000\n",
       "mean   -17.159041  -23.283186  -32.411765  -36.603175\n",
       "std      9.422331   11.262085   14.097464   15.243814\n",
       "min    -60.000000  -70.000000  -80.000000  -95.000000\n",
       "10%    -30.000000  -35.000000  -50.000000  -55.000000\n",
       "25%    -20.000000  -30.000000  -40.000000  -45.000000\n",
       "50%    -15.000000  -20.000000  -30.000000  -35.000000\n",
       "75%    -10.000000  -15.000000  -25.000000  -25.000000\n",
       "90%     -5.000000  -10.000000  -15.000000  -20.000000\n",
       "max     10.000000    5.000000    5.000000    5.000000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### statistics for best intensity rapid intensification (BRI)\n",
    "## (\"observed\" RI)\n",
    "\n",
    "print(\"Statistics for storms with best intensity rapid intensification:\")\n",
    "print(\"================================================================\")\n",
    "\n",
    "bri_num_events = df_ri.loc[df_ri['BRI'] == True]['BRI_count'].sum()\n",
    "bri_forecast_count = len(df_ri.loc[df_ri['BRI'] == True])\n",
    "print(f\"Number of best intensity rapid intensification events on valid hours: {bri_num_events}\")\n",
    "print(f\"Number of forecasts with a best intensity rapid intensification event on a valid hour: {bri_forecast_count}\")\n",
    "bri_storm_ids = set()\n",
    "for idx in df_ri.loc[df_ri['BRI'] == True].index:\n",
    "    bri_storm_ids.add(df_ri.at[idx,'STMID'])\n",
    "print(f\"{len(bri_storm_ids)} Storms with best intensity rapid intensification:\")\n",
    "print(\"\")\n",
    "print(bri_storm_ids)\n",
    "print(\"\")\n",
    "\n",
    "bri_errors = {}\n",
    "print(\"Number of best intensity rapid intensification events for each forecast valid hour:\")\n",
    "for column_name in best_intensity_rapid_intensification_column_name_to_hour.keys():\n",
    "    bri_rows = df_ri.loc[df_ri[column_name] == True]\n",
    "    count = len(bri_rows)\n",
    "    if count > 0:\n",
    "        print(f\"{column_name} : {count}\")\n",
    "    \n",
    "    valid_h = best_intensity_rapid_intensification_column_name_to_hour[column_name]\n",
    "    intensity_err_column_name = intensity_err_hour_to_column_name[valid_h]\n",
    "    bri_errors[valid_h] = []\n",
    "    for idx in bri_rows.index:\n",
    "        prev_bri = bri_errors[valid_h]\n",
    "        intensity_err = bri_rows.at[idx,intensity_err_column_name]\n",
    "        prev_bri.append(intensity_err)\n",
    "        bri_errors[valid_h] = prev_bri\n",
    "\n",
    "# remove empty keys\n",
    "bri_errors = dict((k, v) for k, v in bri_errors.items() if v)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Table 2.\")\n",
    "# convert to dataframe and compute some stats\n",
    "print(\"Forecast intensity error for best intensity rapid intensification (columns are forecast valid hours):\")\n",
    "df_bri_errors = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in bri_errors.items() ]))\n",
    "df_bri_errors.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3bedfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "64224666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic statistics for all storms\n",
      "===============================\n",
      "Total storms: 545\n",
      "\n",
      "% of all storms with best intensity rapid intensification: 33.21 %\n",
      "% of all storms with no best intensity rapid intensification: 66.79 %\n",
      "\n",
      "% of all storms with forecast rapid intensification: 11.93 %\n",
      "% of all storms with no forecast rapid intensification: 88.07 %\n"
     ]
    }
   ],
   "source": [
    "### Basic statistics for number of storms and RI storms\n",
    "print(\"Basic statistics for all storms\")\n",
    "print(\"===============================\")\n",
    "\n",
    "all_storm_ids = set(df_ri['STMID'].to_list())\n",
    "num_storms = len(all_storm_ids)\n",
    "pct_bri = 100.0 * len(bri_storm_ids) / num_storms\n",
    "pct_no_bri = 100.0 - pct_bri\n",
    "pct_fri = 100.0 * len(fri_storm_ids) / num_storms\n",
    "pct_no_fri = 100.0 - pct_fri\n",
    "print(f\"Total storms: {num_storms}\")\n",
    "print(\"\")\n",
    "print(f\"% of all storms with best intensity rapid intensification: {pct_bri:2.2f} %\")\n",
    "print(f\"% of all storms with no best intensity rapid intensification: {pct_no_bri:2.2f} %\")\n",
    "print(\"\")\n",
    "print(f\"% of all storms with forecast rapid intensification: {pct_fri:2.2f} %\")\n",
    "print(f\"% of all storms with no forecast rapid intensification: {pct_no_fri:2.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafa6bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "791ad119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for storms with no best intensity rapid intensification:\n",
      "===================================================================\n",
      "Number of best intensity no rapid intensification events on valid hours: 113670\n",
      "Number of forecasts with no best intensity rapid intensification event on a valid hour: 11367\n",
      "364 Storms with no best intensity rapid intensification:\n",
      "\n",
      "{'AL122008', 'AL082009', 'AL081994', 'AL072003', 'AL092009', 'AL082000', 'AL021993', 'AL062011', 'AL132008', 'AL032007', 'AL232020', 'AL032019', 'AL111990', 'AL102005', 'AL052004', 'AL092003', 'AL012018', 'AL142021', 'AL202021', 'AL172017', 'AL012022', 'AL192017', 'AL092012', 'AL222005', 'AL011998', 'AL182003', 'AL282005', 'AL132021', 'AL041993', 'AL032011', 'AL102007', 'AL071999', 'AL022013', 'AL102004', 'AL062019', 'AL101993', 'AL112018', 'AL132011', 'AL102021', 'AL022020', 'AL192011', 'AL021992', 'AL012014', 'AL142007', 'AL152022', 'AL102011', 'AL052010', 'AL071989', 'AL101999', 'AL042010', 'AL042017', 'AL031992', 'AL072019', 'AL122012', 'AL071991', 'AL082010', 'AL012013', 'AL182017', 'AL052006', 'AL141989', 'AL192003', 'AL162000', 'AL072012', 'AL052020', 'AL162019', 'AL111998', 'AL062016', 'AL012007', 'AL022010', 'AL012005', 'AL172012', 'AL052003', 'AL122003', 'AL142002', 'AL011999', 'AL132022', 'AL122020', 'AL062003', 'AL101989', 'AL132016', 'AL012015', 'AL111995', 'AL042002', 'AL112011', 'AL081995', 'AL151989', 'AL022003', 'AL071992', 'AL011996', 'AL162003', 'AL112008', 'AL042012', 'AL042003', 'AL111999', 'AL032020', 'AL212021', 'AL042019', 'AL142003', 'AL122015', 'AL042006', 'AL192010', 'AL102020', 'AL092014', 'AL242005', 'AL162001', 'AL152012', 'AL032009', 'AL121990', 'AL022012', 'AL011991', 'AL012009', 'AL102008', 'AL302020', 'AL012003', 'AL081989', 'AL092016', 'AL062020', 'AL032013', 'AL232005', 'AL112021', 'AL022005', 'AL212003', 'AL041991', 'AL152018', 'AL021997', 'AL082013', 'AL081998', 'AL122016', 'AL111996', 'AL012010', 'AL132001', 'AL012012', 'AL202019', 'AL182020', 'AL202011', 'AL212020', 'AL052014', 'AL092000', 'AL062013', 'AL082005', 'AL152020', 'AL112019', 'AL051993', 'AL132005', 'AL042013', 'AL141990', 'AL242020', 'AL022004', 'AL102022', 'AL052009', 'AL052013', 'AL011994', 'AL082021', 'AL022007', 'AL162021', 'AL212005', 'AL162005', 'AL021991', 'AL092019', 'AL131990', 'AL061995', 'AL051999', 'AL022019', 'AL142019', 'AL082019', 'AL121994', 'AL192012', 'AL061994', 'AL062017', 'AL062012', 'AL172022', 'AL031995', 'AL061999', 'AL031997', 'AL021994', 'AL121996', 'AL012001', 'AL041995', 'AL152005', 'AL142012', 'AL152013', 'AL162004', 'AL112013', 'AL061990', 'AL042014', 'AL102016', 'AL132013', 'AL052018', 'AL152011', 'AL121989', 'AL082007', 'AL081997', 'AL122001', 'AL012020', 'AL112005', 'AL052001', 'AL052007', 'AL061993', 'AL202003', 'AL092002', 'AL182000', 'AL121998', 'AL012017', 'AL181995', 'AL142022', 'AL142013', 'AL092005', 'AL032022', 'AL312005', 'AL071996', 'AL082011', 'AL132018', 'AL172020', 'AL172003', 'AL081990', 'AL081992', 'AL062009', 'AL082018', 'AL041997', 'AL152010', 'AL302005', 'AL022009', 'AL012000', 'AL072014', 'AL141999', 'AL022000', 'AL062022', 'AL151999', 'AL052000', 'AL011992', 'AL112007', 'AL072002', 'AL072005', 'AL192021', 'AL032021', 'AL032003', 'AL142005', 'AL102015', 'AL092010', 'AL022014', 'AL162020', 'AL022021', 'AL112002', 'AL031994', 'AL172011', 'AL192005', 'AL011993', 'AL081991', 'AL082004', 'AL021989', 'AL162008', 'AL172007', 'AL102006', 'AL062008', 'AL012019', 'AL022016', 'AL031993', 'AL102013', 'AL112022', 'AL122019', 'AL192000', 'AL072020', 'AL101991', 'AL032006', 'AL152003', 'AL082017', 'AL091997', 'AL162010', 'AL072004', 'AL042016', 'AL021990', 'AL102012', 'AL112020', 'AL051989', 'AL162012', 'AL022006', 'AL082015', 'AL062002', 'AL152004', 'AL211995', 'AL062000', 'AL121995', 'AL122013', 'AL172001', 'AL061998', 'AL042000', 'AL151990', 'AL111989', 'AL062005', 'AL041990', 'AL052016', 'AL262005', 'AL092018', 'AL052008', 'AL052011', 'AL091992', 'AL101994', 'AL072015', 'AL062014', 'AL182019', 'AL252020', 'AL012008', 'AL021999', 'AL032015', 'AL032010', 'AL022017', 'AL172021', 'AL061997', 'AL022002', 'AL062021', 'AL092015', 'AL042020', 'AL012002', 'AL022015', 'AL071990', 'AL172019', 'AL082001', 'AL152021', 'AL102010', 'AL042011', 'AL032017', 'AL042021', 'AL072007', 'AL042018', 'AL152019', 'AL201995', 'AL152007', 'AL052015', 'AL102018', 'AL142001', 'AL192019', 'AL122018', 'AL092001', 'AL032016', 'AL112003', 'AL172005', 'AL161995', 'AL031989', 'AL071994', 'AL121999', 'AL091990', 'AL051991', 'AL101992', 'AL112016', 'AL102009', 'AL051994', 'AL142011', 'AL022001', 'AL091991', 'AL122002', 'AL032002', 'AL012011', 'AL111991', 'AL061996', 'AL041989', 'AL091994', 'AL022022', 'AL052017', 'AL122022', 'AL072013', 'AL142008', 'AL082003', 'AL142004', 'AL141995'}\n",
      "\n",
      "\n",
      "Table 3.\n",
      "Forecast intensity error for best intensity no rapid intensification (columns are forecast valid hours):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>96</th>\n",
       "      <th>120</th>\n",
       "      <th>144</th>\n",
       "      <th>168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9923.000000</td>\n",
       "      <td>8940.000000</td>\n",
       "      <td>7935.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>6155.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>4792.000000</td>\n",
       "      <td>2439.000000</td>\n",
       "      <td>1880.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.746246</td>\n",
       "      <td>0.928971</td>\n",
       "      <td>1.975425</td>\n",
       "      <td>2.147857</td>\n",
       "      <td>2.086109</td>\n",
       "      <td>1.188467</td>\n",
       "      <td>1.387730</td>\n",
       "      <td>-0.194752</td>\n",
       "      <td>-1.348404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.040700</td>\n",
       "      <td>7.709195</td>\n",
       "      <td>10.983638</td>\n",
       "      <td>13.524659</td>\n",
       "      <td>15.970980</td>\n",
       "      <td>13.401742</td>\n",
       "      <td>20.704668</td>\n",
       "      <td>21.711836</td>\n",
       "      <td>23.912280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-35.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-65.000000</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            12           24           36           48   \\\n",
       "count  9923.000000  8940.000000  7935.000000  7000.000000  6155.000000   \n",
       "mean     -0.746246     0.928971     1.975425     2.147857     2.086109   \n",
       "std       4.040700     7.709195    10.983638    13.524659    15.970980   \n",
       "min     -35.000000   -30.000000   -45.000000   -50.000000   -65.000000   \n",
       "10%      -5.000000   -10.000000   -10.000000   -15.000000   -20.000000   \n",
       "25%       0.000000    -5.000000    -5.000000    -5.000000   -10.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     5.000000    10.000000    10.000000    10.000000   \n",
       "90%       5.000000    10.000000    15.000000    20.000000    20.000000   \n",
       "max      30.000000    50.000000    75.000000    85.000000    95.000000   \n",
       "\n",
       "              60           72           96           120  144  168  \n",
       "count  711.000000  4792.000000  2439.000000  1880.000000  0.0  0.0  \n",
       "mean     1.188467     1.387730    -0.194752    -1.348404  NaN  NaN  \n",
       "std     13.401742    20.704668    21.711836    23.912280  NaN  NaN  \n",
       "min    -50.000000   -90.000000   -90.000000  -100.000000  NaN  NaN  \n",
       "10%    -15.000000   -25.000000   -25.000000   -30.000000  NaN  NaN  \n",
       "25%     -5.000000   -10.000000   -10.000000   -15.000000  NaN  NaN  \n",
       "50%      0.000000     0.000000     0.000000     0.000000  NaN  NaN  \n",
       "75%     10.000000    15.000000    15.000000    15.000000  NaN  NaN  \n",
       "90%     15.000000    25.000000    25.000000    25.000000  NaN  NaN  \n",
       "max     40.000000    85.000000    90.000000    90.000000  NaN  NaN  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Statistics for storms with no best intensity rapid intensification\n",
    "## (\"observed\" NO RI)\n",
    "\n",
    "no_bri_storm_ids = all_storm_ids.difference(bri_storm_ids)\n",
    "# the number of valid forecast hour columns (including base time)\n",
    "num_valid_hour_columns = len(best_intensity_rapid_intensification_hour_to_column_name)\n",
    "\n",
    "df_no_bri = df_ri.loc[df_ri['BRI'] == False]\n",
    "no_bri_num_events = (len(df_no_bri) * (num_valid_hour_columns - 1))\n",
    "\n",
    "# subtract one since the base time can never have rapid intensification\n",
    "no_bri_forecast_count = len(df_no_bri)\n",
    "\n",
    "print(\"Statistics for storms with no best intensity rapid intensification:\")\n",
    "print(\"===================================================================\")\n",
    "print(f\"Number of best intensity no rapid intensification events on valid hours: {no_bri_num_events}\")\n",
    "print(f\"Number of forecasts with no best intensity rapid intensification event on a valid hour: {no_bri_forecast_count}\")\n",
    "print(f\"{len(no_bri_storm_ids)} Storms with no best intensity rapid intensification:\")\n",
    "print(\"\")\n",
    "print(no_bri_storm_ids)\n",
    "print(\"\")\n",
    "\n",
    "no_bri_errors = {}\n",
    "for [valid_h, column_name] in intensity_err_hour_to_column_name.items():\n",
    "    no_bri_errors[valid_h] = []\n",
    "    for idx in df_no_bri.index:\n",
    "        prev_no_bri = no_bri_errors[valid_h]\n",
    "        intensity_err = df_no_bri.at[idx, column_name]\n",
    "        prev_no_bri.append(intensity_err)\n",
    "        no_bri_errors[valid_h] = prev_no_bri\n",
    "\n",
    "# remove empty keys\n",
    "no_bri_errors = dict((k, v) for k, v in no_bri_errors.items() if v)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Table 3.\")\n",
    "# convert to dataframe and compute some stats\n",
    "print(\"Forecast intensity error for best intensity no rapid intensification (columns are forecast valid hours):\")\n",
    "df_no_bri_errors = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in no_bri_errors.items() ]))\n",
    "df_no_bri_errors.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a5d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9299a78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for storms with no best intensity rapid intensification but with forecast RI:\n",
      "========================================================================================\n",
      "Number of forecast rapid intensification events on valid hours: 62\n",
      "Number of forecasts with rapid intensification event on a valid hour: 49\n",
      "10 Storms with forecast rapid intensification:\n",
      "\n",
      "{'AL051993', 'AL071992', 'AL152022', 'AL011994', 'AL052000', 'AL061996', 'AL111996', 'AL132022', 'AL052001', 'AL062002'}\n",
      "\n",
      "Number of best intensity rapid intensification events for each forecast valid hour:\n",
      "12hFRI : 42\n",
      "24hFRI : 18\n",
      "48hFRI : 2\n",
      "\n",
      "Table 4.\n",
      "Forecast intensity error for best intensity no rapid intensification but with forecast RI\n",
      "(columns are forecast valid hours):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.428571</td>\n",
       "      <td>16.111111</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.265498</td>\n",
       "      <td>14.095844</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              12         24    48\n",
       "count  42.000000  18.000000   2.0\n",
       "mean    6.428571  16.111111  15.0\n",
       "std     7.265498  14.095844   0.0\n",
       "min    -5.000000  -5.000000  15.0\n",
       "10%     0.000000   5.000000  15.0\n",
       "25%     1.250000   5.000000  15.0\n",
       "50%     5.000000  15.000000  15.0\n",
       "75%    10.000000  20.000000  15.0\n",
       "90%    15.000000  38.000000  15.0\n",
       "max    30.000000  45.000000  15.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Statistics for storms with no best intensity rapid intensification but with forecast rapid intensification\n",
    "## (\"observed\" NO RI, YES forecast RI)\n",
    "\n",
    "no_bri_yes_fri_storm_ids = no_bri_storm_ids.intersection(fri_storm_ids)\n",
    "# the number of valid forecast hour columns (including base time)\n",
    "num_valid_hour_columns = len(best_intensity_rapid_intensification_hour_to_column_name)\n",
    "\n",
    "df_no_bri_yes_fri = df_no_bri_yes_fri = df_ri.loc[(df_ri['BRI'] == False) & (df_ri['FRI'] == True)]\n",
    "no_bri_yes_fri_num_events = df_no_bri_yes_fri['FRI_count'].sum()\n",
    "no_bri_yes_fri_forecast_count = len(df_no_bri_yes_fri)\n",
    "\n",
    "# subtract one since the base time can never have rapid intensification\n",
    "no_bri_yes_fri_forecast_count = len(df_no_bri_yes_fri)\n",
    "\n",
    "print(\"Statistics for storms with no best intensity rapid intensification but with forecast RI:\")\n",
    "print(\"========================================================================================\")\n",
    "print(f\"Number of forecast rapid intensification events on valid hours: {no_bri_yes_fri_num_events}\")\n",
    "print(f\"Number of forecasts with rapid intensification event on a valid hour: {no_bri_yes_fri_forecast_count}\")\n",
    "print(f\"{len(no_bri_yes_fri_storm_ids)} Storms with forecast rapid intensification:\")\n",
    "print(\"\")\n",
    "print(no_bri_yes_fri_storm_ids)\n",
    "print(\"\")\n",
    "\n",
    "no_bri_yes_fri_errors = {}\n",
    "print(\"Number of best intensity rapid intensification events for each forecast valid hour:\")\n",
    "for column_name in forecast_rapid_intensification_column_name_to_hour.keys():\n",
    "    no_bri_yes_fri_rows = df_no_bri_yes_fri.loc[df_no_bri_yes_fri[column_name] == True]\n",
    "    count = len(no_bri_yes_fri_rows)\n",
    "    if count > 0:\n",
    "        print(f\"{column_name} : {count}\")\n",
    "    \n",
    "    valid_h = forecast_rapid_intensification_column_name_to_hour[column_name]\n",
    "    intensity_err_column_name = intensity_err_hour_to_column_name[valid_h]\n",
    "    no_bri_yes_fri_errors[valid_h] = []\n",
    "    for idx in no_bri_yes_fri_rows.index:\n",
    "        prev_no_bri_yes_fri = no_bri_yes_fri_errors[valid_h]\n",
    "        intensity_err = no_bri_yes_fri_rows.at[idx,intensity_err_column_name]\n",
    "        prev_no_bri_yes_fri.append(intensity_err)\n",
    "        no_bri_yes_fri_errors[valid_h] = prev_no_bri_yes_fri\n",
    "\n",
    "# remove empty keys\n",
    "no_bri_yes_fri_errors = dict((k, v) for k, v in no_bri_yes_fri_errors.items() if v)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Table 4.\")\n",
    "# convert to dataframe and compute some stats\n",
    "print(\"Forecast intensity error for best intensity no rapid intensification but with forecast RI\\n(columns are forecast valid hours):\")\n",
    "df_no_bri_yes_fri_errors = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in no_bri_yes_fri_errors.items() ]))\n",
    "df_no_bri_yes_fri_errors.describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8f97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d2289f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI Storms:\n",
      "% Storms with best intensity RI that were forecast with RI (TP): 30.39 % (55)\n",
      "% Storms with best intensity RI that were not forecast with RI (FN): 69.61 % (126)\n",
      "\n",
      "Non-RI Storms:\n",
      "% Storms with no best intensity RI that were forecast with RI (FP): 2.75 % (10)\n",
      "% Storms with no best intensity RI that were not forecast with RI (TN): 97.25 % (354)\n"
     ]
    }
   ],
   "source": [
    "# Note: storms forecast RI that also have best intensity RI (not necessarily at the correct valid time)\n",
    "\n",
    "no_bri_storm_ids = all_storm_ids.difference(bri_storm_ids)\n",
    "no_fri_storm_ids = all_storm_ids.difference(fri_storm_ids)\n",
    "\n",
    "# naive validation since forecast may have gotten RI for the wrong time/location/reason\n",
    "tp = len(fri_storm_ids.intersection(bri_storm_ids))\n",
    "pct_tp = 100.0 * tp / len(bri_storm_ids)\n",
    "fn = len(no_fri_storm_ids.intersection(bri_storm_ids))\n",
    "pct_fn = 100.0 * fn / len(bri_storm_ids)\n",
    "\n",
    "print(\"RI Storms:\")\n",
    "print(f\"% Storms with best intensity RI that were forecast with RI (TP): {pct_tp:2.2f} % ({tp})\")\n",
    "print(f\"% Storms with best intensity RI that were not forecast with RI (FN): {pct_fn:2.2f} % ({fn})\")\n",
    "print(\"\")\n",
    "print(\"Non-RI Storms:\")\n",
    "fp = len(fri_storm_ids.intersection(no_bri_storm_ids))\n",
    "pct_fp = 100.0 * fp / len(no_bri_storm_ids)\n",
    "tn = len(no_fri_storm_ids.intersection(no_bri_storm_ids))\n",
    "pct_tn = 100.0 * tn / len(no_bri_storm_ids)\n",
    "print(f\"% Storms with no best intensity RI that were forecast with RI (FP): {pct_fp:2.2f} % ({fp})\")\n",
    "print(f\"% Storms with no best intensity RI that were not forecast with RI (TN): {pct_tn:2.2f} % ({tn})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a52c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb424385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initial thoughts...\n",
    "\n",
    "# Hypothetical basis for considering probabilities using OFCL intensities alone from forecast advisories:\n",
    "#   when calculating base rates using the above tables and statistics, check if there is RI in the forecast:\n",
    "#   if there is RI in the forecast:\n",
    "#      note that % RI false positives is only ~ 3%: so reference,\n",
    "#         2.75 % to weight (pct_fp) on Table 4 calculations\n",
    "#         97.25 % to weight (pct_fp) on Table 1 calculations\n",
    "#\n",
    "#   if there is no RI in the forecast:\n",
    "#      note only ~33% of storms have RI historically (in the last ~30 years): so reference,\n",
    "#         66.79 % to weight (pct_no_bri) on Table 3 calculations\n",
    "#         33.21 % to weight (pct_bri) on Table 2 calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b82e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1249139",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
